{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9YZ9oalKHLs"
      },
      "outputs": [],
      "source": [
        "#  Imports\n",
        "import time\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wandb\n",
        "\n",
        "# Silence benign warnings that clutter output\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# For perfect reproducibility (optional – comment if not desired)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "#  Hyper‑parameters (same variable name `h_params` required downstream)\n",
        "\n",
        "h_params = {\n",
        "    \"epochs\": 10,\n",
        "    \"learning_rate\": [0.0001],\n",
        "    \"batch_size\": 128,\n",
        "    \"num_of_filter\": 64,\n",
        "    \"filter_size\": [3, 3, 3, 3, 3],\n",
        "    \"actv_func\": \"gelu\",\n",
        "    \"filter_multiplier\": 2,\n",
        "    \"data_augumentation\": False,\n",
        "    \"batch_normalization\": True,\n",
        "    \"dropout\": 0.4,\n",
        "    \"conv_layers\": 5,\n",
        "    \"dense_layer_size\": 256,\n",
        "}\n",
        "\n",
        "IMAGE_SIZE      = 224          # Target spatial size fed to CNN\n",
        "NUM_OF_CLASSES  = 10           # Dataset has 10 super‑classes\n",
        "CLASS_LABELS    = [\n",
        "    \"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \"Fungi\",\n",
        "    \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"\n",
        "]\n",
        "\n",
        "#  Helper utilities\n",
        "\n",
        "def _get_transforms(aug: bool) -> Tuple[transforms.Compose, transforms.Compose]:\n",
        "    \"\"\"Return (train_tfms, test_tfms) based on augmentation flag.\"\"\"\n",
        "    base_ops = [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))]\n",
        "    aug_ops  = [\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "        transforms.GaussianBlur(kernel_size=3),\n",
        "    ]\n",
        "    to_tensor = [transforms.ToTensor()]\n",
        "\n",
        "    train_ops = base_ops + (aug_ops if aug else []) + to_tensor\n",
        "    test_ops  = base_ops + to_tensor\n",
        "\n",
        "    return transforms.Compose(train_ops), transforms.Compose(test_ops)\n",
        "\n",
        "\n",
        "def _init_wandb_run(config: Dict) -> wandb.wandb_sdk.wandb_run.Run:\n",
        "    \"\"\"Start a uniquely‑named W&B run. Login key expected in env/cli.\"\"\"\n",
        "    wandb.login()                      # Empty key => falls back to env var\n",
        "    run_name = (\n",
        "        f\"{config['actv_func']}_ep_{config['epochs']}\"\n",
        "        f\"_lr_{config['learning_rate']}\"\n",
        "        f\"_init_fltr_cnt_{config['num_of_filter']}\"\n",
        "        f\"_fltr_sz_{config['filter_size']}\"\n",
        "        f\"_fltr_mult_{config['filter_multiplier']}\"\n",
        "        f\"_data_aug_{config['data_augumentation']}\"\n",
        "        f\"_batch_norm_{config['batch_normalization']}\"\n",
        "        f\"_dropout_{config['dropout']}\"\n",
        "        f\"_dense_{config['dense_layer_size']}\"\n",
        "    )\n",
        "    return wandb.init(project=\"DL Assignment 2\", name=run_name, config=config)\n",
        "\n",
        "\n",
        "def split_dataset_with_class_distribution(\n",
        "    dataset: ImageFolder, split_ratio: float\n",
        ") -> Tuple[Subset, Subset]:\n",
        "    \"\"\"\n",
        "    Split indices into train/val buckets *per‑class* to preserve distribution.\n",
        "    The ranges are hard‑coded because Nature‑12K data on Kaggle arrives ordered\n",
        "    by class in blocks of 1 000 samples each (last block has 999).\n",
        "    \"\"\"\n",
        "    class_ranges = [(i * 1000, (i + 1) * 1000 - 1) for i in range(10)]\n",
        "    class_ranges[-1] = (9000, 9998)  # adjust final slice size\n",
        "\n",
        "    train_idx, val_idx = [], []\n",
        "    for start, end in class_ranges:\n",
        "        class_ids = list(range(start, end + 1))\n",
        "        split_at  = int(len(class_ids) * split_ratio)\n",
        "        train_idx.extend(class_ids[:split_at])\n",
        "        val_idx.extend(class_ids[split_at:])\n",
        "\n",
        "    return Subset(dataset, train_idx), Subset(dataset, val_idx)\n",
        "\n",
        "\n",
        "def prepare_data(h_params: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Build loaders & meta info.\n",
        "    Adds a redundant sanity‑check printout of dataset sizes that can be\n",
        "    commented out if you dislike the clutter.\n",
        "    \"\"\"\n",
        "    train_tfms, test_tfms = _get_transforms(h_params[\"data_augumentation\"])\n",
        "\n",
        "    # NOTE: update paths if your dataset directory differs\n",
        "    base = Path(\"/kaggle/input/nature/inaturalist_12K\")\n",
        "    train_dir, val_dir = base / \"train\", base / \"val\"\n",
        "\n",
        "    full_train = ImageFolder(train_dir, transform=train_tfms)\n",
        "    train_ds, val_ds = split_dataset_with_class_distribution(full_train, 0.8)\n",
        "\n",
        "    test_ds = ImageFolder(val_dir, transform=test_tfms)  # Kaggle's \"val\" is our test\n",
        "\n",
        "    bs = h_params[\"batch_size\"]\n",
        "    data = {\n",
        "        \"train_len\": len(train_ds),   \"val_len\": len(val_ds),   \"test_len\": len(test_ds),\n",
        "        \"train_loader\": DataLoader(train_ds, batch_size=bs, shuffle=True,  num_workers=2),\n",
        "        \"val_loader\":   DataLoader(val_ds,   batch_size=bs, shuffle=False, num_workers=2),\n",
        "        \"test_loader\":  DataLoader(test_ds,  batch_size=bs, shuffle=False, num_workers=2),\n",
        "    }\n",
        "\n",
        "    # Redundant diagnostic – safe to remove\n",
        "    print(f\"[INFO] Data splits – train:{data['train_len']}  \"\n",
        "          f\"val:{data['val_len']}  test:{data['test_len']}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "# 4. Model definition (class name & attributes unchanged)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, h_params: Dict) -> None:\n",
        "        super().__init__()\n",
        "        self.h_params = h_params\n",
        "\n",
        "        # Dynamically grow filter list\n",
        "        self.filters = [\n",
        "            int(self.h_params[\"num_of_filter\"] * (self.h_params[\"filter_multiplier\"] ** i))\n",
        "            for i in range(5)\n",
        "        ]\n",
        "        print(f\"[DEBUG] Convolution filter counts: {self.filters}\")\n",
        "\n",
        "        # Build sequential conv–>BN blocks\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        self.bn_layers   = nn.ModuleList()\n",
        "\n",
        "        in_ch = 3\n",
        "        for i in range(self.h_params[\"conv_layers\"]):\n",
        "            self.conv_layers.append(nn.Conv2d(in_ch, self.filters[i],\n",
        "                                              kernel_size=self.h_params[\"filter_size\"][i]))\n",
        "            if self.h_params[\"batch_normalization\"]:\n",
        "                self.bn_layers.append(nn.BatchNorm2d(self.filters[i]))\n",
        "            in_ch = self.filters[i]\n",
        "\n",
        "        fmap_side = self._calc_flatten_size(self.h_params[\"filter_size\"], IMAGE_SIZE)\n",
        "        dense_in  = self.filters[-1] * fmap_side * fmap_side\n",
        "\n",
        "        self.fc1 = nn.Linear(dense_in, self.h_params[\"dense_layer_size\"])\n",
        "        self.fc2 = nn.Linear(self.h_params[\"dense_layer_size\"], NUM_OF_CLASSES)\n",
        "\n",
        "        self.dropout = nn.Dropout(self.h_params[\"dropout\"])\n",
        "        self.activation_func = self._get_activation(self.h_params[\"actv_func\"])\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # noqa: D401\n",
        "        \"\"\"Forward pass: conv‑stack → flatten → MLP.\"\"\"\n",
        "        for i in range(self.h_params[\"conv_layers\"]):\n",
        "            x = self.conv_layers[i](x)\n",
        "            if self.h_params[\"batch_normalization\"]:\n",
        "                x = self.bn_layers[i](x)\n",
        "            x = self.activation_func(x)\n",
        "            x = F.max_pool2d(x, 2)   # stride=2 implicitly\n",
        "        x = x.flatten(1)            # (B, ‑1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _get_activation(name: str):\n",
        "        \"\"\"Return functional activation by string.\"\"\"\n",
        "        mapping = {\n",
        "            \"elu\":         F.elu,\n",
        "            \"gelu\":        F.gelu,\n",
        "            \"silu\":        F.silu,\n",
        "            \"selu\":        F.selu,\n",
        "            \"leaky_relu\":  F.leaky_relu,\n",
        "        }\n",
        "        return mapping.get(name, F.relu)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _calc_flatten_size(kernels, size) -> int:\n",
        "        \"\"\"Compute leftover fmap side after (conv → pool)×5.\"\"\"\n",
        "        for k in kernels:  # each conv followed by 2×2 pooling\n",
        "            size = (size - k + 1) // 2\n",
        "        return size\n",
        "\n",
        "\n",
        "# 5. Evaluation helpers\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_testing_model(model: nn.Module, device, loader_data: Dict) -> None:\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    for inputs, labels in loader_data[\"test_loader\"]:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        preds = model(inputs).argmax(dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "\n",
        "    acc = total_correct / loader_data[\"test_len\"]\n",
        "    print(f\"[METRIC] Test accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "def generateGridImage(model: nn.Module, device, loader_data: Dict) -> None:\n",
        "    \"\"\"Log a 10×3 (30‑image) grid with true/pred labels to W&B.\"\"\"\n",
        "    model.eval()\n",
        "    test_iter = iter(loader_data[\"test_loader\"])\n",
        "    imgs, trues, preds = [], [], []\n",
        "\n",
        "    for _ in range(30):\n",
        "        x, y = next(test_iter)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        p = model(x).argmax(1)\n",
        "        imgs.extend(x.cpu())\n",
        "        trues.extend(y.cpu())\n",
        "        preds.extend(p.cpu())\n",
        "\n",
        "    fig, axs = plt.subplots(10, 3, figsize=(12, 40))\n",
        "    for idx, ax in enumerate(axs.ravel()):\n",
        "        ax.imshow(np.transpose(imgs[idx], (1, 2, 0)))\n",
        "        ax.set_axis_off()\n",
        "        ax.set_title(f\"T:{CLASS_LABELS[trues[idx]]}\\nP:{CLASS_LABELS[preds[idx]]}\",\n",
        "                     fontdict={\"fontsize\": 10})\n",
        "    plt.tight_layout()\n",
        "    wandb.log({\"Predictions\": wandb.Image(plt.gcf())})\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# 6. Training loop\n",
        "\n",
        "def train(h_params: Dict, data: Dict) -> None:\n",
        "    start_ts = time.time()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = CNN(h_params).to(device)\n",
        "\n",
        "    # DataParallel helps on multi‑GPU nodes; harmless on single GPU\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = torch.nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
        "\n",
        "    loss_fn  = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"learning_rate\"])\n",
        "\n",
        "    for epoch in range(h_params[\"epochs\"]):\n",
        "        model.train()\n",
        "        epoch_loss = epoch_correct = 0\n",
        "\n",
        "        for step, (x, y) in enumerate(data[\"train_loader\"]):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out   = model(x)\n",
        "            loss  = loss_fn(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss    += loss.item()\n",
        "            epoch_correct += (out.argmax(1) == y).sum().item()\n",
        "\n",
        "            # Redundant intra‑epoch message every 10 mini‑batches\n",
        "            if step % 10 == 0:\n",
        "                batch_acc = (out.argmax(1) == y).float().mean().item()\n",
        "                print(f\"Ep{epoch:<2d} • step {step:<4d} \"\n",
        "                      f\"batch_acc:{batch_acc:5.3f}  loss:{loss.item():6.4f}\")\n",
        "\n",
        "        # ── validation ────────────────────────────────────────────────────\n",
        "        model.eval()\n",
        "        val_loss = val_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in data[\"val_loader\"]:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out  = model(x)\n",
        "                val_loss    += loss_fn(out, y).item()\n",
        "                val_correct += (out.argmax(1) == y).sum().item()\n",
        "\n",
        "        # epoch‑level metrics\n",
        "        train_acc = epoch_correct / data[\"train_len\"]\n",
        "        val_acc   = val_correct   / data[\"val_len\"]\n",
        "\n",
        "        print(f\"[EPOCH {epoch}] \"\n",
        "              f\"train_acc:{train_acc:.4f}  val_acc:{val_acc:.4f}  \"\n",
        "              f\"train_loss:{epoch_loss/len(data['train_loader']):.4f}  \"\n",
        "              f\"val_loss:{val_loss/len(data['val_loader']):.4f}\")\n",
        "\n",
        "        # W&B logging\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_accuracy\":   val_acc,\n",
        "            \"train_loss\":     epoch_loss / len(data[\"train_loader\"]),\n",
        "            \"val_loss\":       val_loss   / len(data[\"val_loader\"]),\n",
        "        })\n",
        "\n",
        "        # optional: free VRAM between epochs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"[DONE] Training completed in {(time.time() - start_ts)/60:.1f} min\")\n",
        "    torch.save(model.state_dict(), \"bestmodel.pth\")\n",
        "\n",
        "    # Uncomment to evaluate and/or visualise predictions\n",
        "    # evaluate_testing_model(model, device, data)\n",
        "    # generateGridImage(model, device, data)\n",
        "\n",
        "\n",
        "# 7. Main entry point (run/sweep)\n",
        "if __name__ == \"__main__\":\n",
        "    # Regular run (single config) ------------------------------------------------\n",
        "    data = prepare_data(h_params)\n",
        "    run  = _init_wandb_run(h_params)\n",
        "    train(h_params, data)\n",
        "    run.finish()\n",
        "\n",
        "    # Sweep run (Bayesian search) ------------------------------------------------\n",
        "    sweep_params = {\n",
        "        \"method\": \"bayes\",\n",
        "        \"name\":   \"DL assn 2 sweep\",\n",
        "        \"metric\": {\"goal\": \"maximize\", \"name\": \"val_accuracy\"},\n",
        "        \"parameters\": {\n",
        "            \"epochs\":              {\"values\": [10]},\n",
        "            \"learning_rate\":       {\"values\": [0.0001, 0.001]},\n",
        "            \"batch_size\":          {\"values\": [32, 64]},\n",
        "            \"num_of_filter\":       {\"values\": [16, 32, 64]},\n",
        "            \"filter_size\":         {\"values\": [[3]*5, [5]*5, [7]*5,\n",
        "                                               [11, 9, 7, 5, 3], [3, 5, 7, 9, 11]]},\n",
        "            \"actv_func\":           {\"values\": [\"elu\", \"gelu\", \"leaky_relu\", \"selu\"]},\n",
        "            \"filter_multiplier\":   {\"values\": [1, 2]},\n",
        "            \"data_augumentation\":  {\"values\": [False]},\n",
        "            \"batch_normalization\": {\"values\": [True, False]},\n",
        "            \"dropout\":             {\"values\": [0, 0.1, 0.2]},\n",
        "            \"dense_layer_size\":    {\"values\": [64, 128, 256]},\n",
        "            \"conv_layers\":         {\"values\": [5]},\n",
        "        },\n",
        "    }\n",
        "\n",
        "    sweep_id = wandb.sweep(sweep=sweep_params, project=\"DL Assignment 2\")\n",
        "\n",
        "    def main():\n",
        "        wandb.init(project=\"DL Assignment 2\")            # loads sweep config\n",
        "        cfg = dict(wandb.config)                        # keep original var name\n",
        "        d   = prepare_data(cfg)\n",
        "        train(cfg, d)\n",
        "\n",
        "    # Launch up to 10 sweep trials\n",
        "    wandb.agent(sweep_id, function=main, count=10)\n"
      ]
    }
  ]
}