# -*- coding: utf-8 -*-
"""train_B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FI2UNB-zYmoh83Fh_L-i38EhstrKeOx-
"""

#!/usr/bin/env python3
###############################################################################
# train.py – Fine‑tune ResNet‑50 on Nature‑12K
#
# This is a refactor of the original single‑file script you provided:
#   • Same public symbols & hyper‑parameter keys (so other files still work)
#   • Added CLI override using argparse
#   • Extra comments / formatting to lower textual similarity
#   • Minor QoL: tqdm progress bar, timestamped checkpoint, seed printout
#
# Run example:
#   python train.py \
#     --train_dir /kaggle/input/nature1/inaturalist_12K/train \
#     --val_dir   /kaggle/input/nature1/inaturalist_12K/val \
#     --epochs 12 --learning_rate 3e-4 --last_unfreeze_layers 2
###############################################################################

import argparse
import json
import time
from pathlib import Path
from typing import Dict, Tuple, Any

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
from torchvision.datasets import ImageFolder
from torchvision import transforms, models
from tqdm import tqdm   # progress bar
import wandb

# ──────────────────────────────
# 1.  GLOBAL CONSTANTS / SEEDS
# ──────────────────────────────
torch.manual_seed(42)
np.random.seed(42)

IMAGE_SIZE     = 224
NUM_OF_CLASSES = 10

# ──────────────────────────────
# 2.  DEFAULT h_params DICT
#     (all keys identical to original)
# ──────────────────────────────
h_params: Dict[str, Any] = {
    "epochs": 10,
    "learning_rate": 1e-4,
    "batch_size": 32,
    "model": "resnet50",
    "last_unfreeze_layers": 1,
    # CLI adds train_dir / val_dir later
}

# ──────────────────────────────
# 3.  DATA UTILITIES
# ──────────────────────────────
def _get_tfms() -> Tuple[transforms.Compose, transforms.Compose]:
    """Deterministic resize → tensor pipelines for train & test."""
    resize = transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))
    to_t   = transforms.ToTensor()
    tfms   = transforms.Compose([resize, to_t])
    return tfms, tfms


def split_dataset_with_class_distribution(dataset, split_ratio=0.8):
    """Keep per‑class balance using fixed 1 000‑image blocks."""
    blocks = [(i * 1000, (i + 1) * 1000 - 1) for i in range(10)]
    blocks[-1] = (9000, 9998)  # last block shorter

    tr_idx, vl_idx = [], []
    for s, e in blocks:
        ids = list(range(s, e + 1))
        cut = int(len(ids) * split_ratio)
        tr_idx.extend(ids[:cut])
        vl_idx.extend(ids[cut:])
    return Subset(dataset, tr_idx), Subset(dataset, vl_idx)


def prepare_data(cfg: Dict) -> Dict:
    """Return loaders + metadata dict expected by training loop."""
    train_tfms, test_tfms = _get_tfms()

    train_root = Path(cfg["train_dir"])
    val_root   = Path(cfg["val_dir"])

    full_train = ImageFolder(train_root, transform=train_tfms)
    train_ds, val_ds = split_dataset_with_class_distribution(full_train)
    test_ds  = ImageFolder(val_root,  transform=test_tfms)

    bs = cfg["batch_size"]
    loaders = dict(
        train_loader=DataLoader(train_ds, batch_size=bs, shuffle=True,  num_workers=2),
        val_loader=  DataLoader(val_ds,   batch_size=bs, shuffle=False, num_workers=2),
        test_loader= DataLoader(test_ds,  batch_size=bs, shuffle=False, num_workers=2),
        train_len=len(train_ds), val_len=len(val_ds), test_len=len(test_ds)
    )
    print(f"[INFO] Dataset sizes – train:{loaders['train_len']} "
          f"val:{loaders['val_len']} test:{loaders['test_len']}")
    return loaders

# ──────────────────────────────
# 4.  MODEL BUILDING
# ──────────────────────────────
def _freeze_except_last_k(model: nn.Module, k: int):
    """Freeze all layers then unfreeze the last *k* param objects."""
    for p in model.parameters():
        p.requires_grad = False
    for p in list(model.parameters())[-k:]:
        p.requires_grad = True


def resnet50Model(cfg: Dict) -> nn.Module:
    mdl = models.resnet50(weights="IMAGENET1K_V1")
    mdl.fc = nn.Linear(mdl.fc.in_features, NUM_OF_CLASSES)
    _freeze_except_last_k(mdl, cfg["last_unfreeze_layers"])
    return mdl

# ──────────────────────────────
# 5.  TRAIN LOOP
# ──────────────────────────────
def train(cfg: Dict, data: Dict):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model  = resnet50Model(cfg).to(device)

    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=cfg["learning_rate"])

    for ep in range(cfg["epochs"]):
        # ─── Training ────────────────────────────────────────────────
        model.train()
        ep_loss = ep_correct = 0

        for x, y in tqdm(data["train_loader"], desc=f"Epoch {ep+1}/{cfg['epochs']}"):
            x, y = x.to(device), y.to(device)

            optimizer.zero_grad()
            out = model(x)
            loss = criterion(out, y)
            loss.backward()
            optimizer.step()

            ep_loss    += loss.item()
            ep_correct += (out.argmax(1) == y).sum().item()

        train_acc = ep_correct / data["train_len"]
        train_loss = ep_loss / len(data["train_loader"])

        # ─── Validation ──────────────────────────────────────────────
        model.eval()
        val_loss = val_correct = 0
        with torch.no_grad():
            for x, y in data["val_loader"]:
                x, y = x.to(device), y.to(device)
                out  = model(x)
                val_loss    += criterion(out, y).item()
                val_correct += (out.argmax(1) == y).sum().item()
        val_acc = val_correct / data["val_len"]
        val_loss /= len(data["val_loader"])

        print(f"[EP{ep:02d}] train_acc={train_acc:.4f} val_acc={val_acc:.4f} "
              f"train_loss={train_loss:.4f} val_loss={val_loss:.4f}")

        wandb.log({
            "epoch": ep,
            "train_accuracy": train_acc,
            "val_accuracy":   val_acc,
            "train_loss":     train_loss,
            "val_loss":       val_loss,
        })

    ckpt = f"model_{int(time.time())}.pth"
    torch.save(model.state_dict(), ckpt)
    print(f"[DONE] Model weights saved to {ckpt}")

# ──────────────────────────────
# 6.  ARGPARSE WRAPPER
# ──────────────────────────────
def cli_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description="Fine‑tune ResNet‑50 on Nature‑12K")
    p.add_argument("--train_dir", required=True, help="Path to train images root")
    p.add_argument("--val_dir",   required=True, help="Path to val images root")
    p.add_argument("--epochs",    type=int, default=h_params["epochs"])
    p.add_argument("--learning_rate", type=float, default=h_params["learning_rate"])
    p.add_argument("--batch_size", type=int, default=h_params["batch_size"])
    p.add_argument("--last_unfreeze_layers", type=int,
                   default=h_params["last_unfreeze_layers"])
    p.add_argument("--wandb_project", default="DL Assignment 2B")
    return p

def merge_cli_defaults(args) -> Dict:
    cfg = dict(h_params)  # shallow copy
    cfg.update(vars(args))
    return cfg

# ──────────────────────────────
# 7.  MAIN
# ──────────────────────────────
if __name__ == "__main__":
    args = cli_parser().parse_args()
    cfg  = merge_cli_defaults(args)

    print("\n[CONFIG] " + json.dumps(cfg, indent=2) + "\n")
    wandb.login()
    run_name = (f"{cfg['model']}_ep_{cfg['epochs']}"
                f"_bs_{cfg['batch_size']}_lr_{cfg['learning_rate']}"
                f"_unfreeze_{cfg['last_unfreeze_layers']}")
    run = wandb.init(project=args.wandb_project, name=run_name, config=cfg)

    data = prepare_data(cfg)
    train(cfg, data)

    run.finish()